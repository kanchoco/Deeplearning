```
  from torch import nn
  import torch.nn.functional as F
  
  class LeNet5 (nn.Module) :
    def __init__ (self).__init__()
  
  self.feature_extractor = nn.Sequential (
    nn.Conv2d (1, 6, kernel_size = 5, stride = 1), #Convolution
    nn.Tanh(), #activation
    nn.AvgPool2d(kernel_size = 2), # pooling
    nn.Conv2d (6, 16, kernel_size = 5, stride = 1),
    nn.Tanh(),
    nn.AvgPool2d(kernel_size = 2),
    nn.Conv2d (16, 120, kernel_size = 5, stride = 1),
    nn.Tanh()
  )
  self.calssifier = nn.Sequential (
    nn.Linear(120, 84),
    nn.Tanh()
    nn.Linear(84, 10)
  )
  def forward (self, x) : 
    x = self.feature_extractor (x)
    x = torch.flatten(x, 1)
    x = self.classifier(x)
    return F.softmax(x, dim-1)
  
  # 데이터 로딩
  from torchvision import transforms
  from torchvision import datasets
  
  data_transform = transforms.Compose([
    transforms.Resize((32, 32)),
    transforms.ToTensor(),
  ])
  datapath = '/data/MNIST'
  
  train_data = datasets.MNIST(datapath, train=True, download=True, transform=data_transform)
  
  # Training
  
  # 환경설정
  RANDOM_SEED = 42
  LEARNING_RATE = 1e-4
  BATCH_SIZE = 32
  EPOCH = 20
  IMAGE_SIZE = 32
  
  # Data
  train_loader = DataLoader (dataset=train_data, batch_size = BATCH_SIZE, shuffle = True)
  # Model
  model = LeNet5().to(DEVICE)
  # Loss
  criterion = nn.CrossEntropyLoss()
  # Optimizer
  optimizer = torch.optim.Adam(model.parameters(), 
              lr = LEARNING_RATE)
  
  # Training
  for epoch in range(0, EPOCH) :
    for x, y in train_loader :
      optimizer.zero_grad()
  
      y = y.to (device)
      y_pred = model (x)
      loss = criterion (y_pred, y)
  
      loss.backward()
  
      optimizer.step()
      optimizer.zero_grad()
```
